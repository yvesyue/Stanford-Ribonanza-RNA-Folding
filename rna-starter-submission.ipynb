{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":51294,"databundleVersionId":6923401,"sourceType":"competition"},{"sourceId":6683601,"sourceType":"datasetVersion","datasetId":3855379},{"sourceId":6822004,"sourceType":"datasetVersion","datasetId":3719560},{"sourceId":7147986,"sourceType":"datasetVersion","datasetId":4126639},{"sourceId":7150221,"sourceType":"datasetVersion","datasetId":4128265},{"sourceId":7183386,"sourceType":"datasetVersion","datasetId":4152346},{"sourceId":142566306,"sourceType":"kernelVersion"}],"dockerImageVersionId":30559,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"It is an example of inference with model trained in [RNA starter kernel](https://www.kaggle.com/code/iafoss/rna-starter)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport os, gc\nimport numpy as np\nfrom tqdm.notebook import tqdm\nimport math\nfrom sklearn.model_selection import KFold\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-12-12T11:13:57.988744Z","iopub.execute_input":"2023-12-12T11:13:57.989102Z","iopub.status.idle":"2023-12-12T11:14:04.019137Z","shell.execute_reply.started":"2023-12-12T11:13:57.989072Z","shell.execute_reply":"2023-12-12T11:14:04.018055Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"MODELS = ['/kaggle/input/example5/example5_0.pth']\nPATH = '/kaggle/input/stanford-ribonanza-rna-folding-converted/'\nbs = 256\nnum_workers = 2\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2023-12-12T11:15:11.751374Z","iopub.execute_input":"2023-12-12T11:15:11.751810Z","iopub.status.idle":"2023-12-12T11:15:11.757683Z","shell.execute_reply.started":"2023-12-12T11:15:11.751776Z","shell.execute_reply":"2023-12-12T11:15:11.756414Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_parquet(os.path.join(PATH,'test_sequences.parquet'))","metadata":{"execution":{"iopub.status.busy":"2023-12-12T11:14:04.031076Z","iopub.execute_input":"2023-12-12T11:14:04.031529Z","iopub.status.idle":"2023-12-12T11:14:08.358442Z","shell.execute_reply.started":"2023-12-12T11:14:04.031484Z","shell.execute_reply":"2023-12-12T11:14:08.357550Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"id_min, id_max, seq = df_test.loc[0, ['id_min','id_max','sequence']]\nid_min, id_max, seq","metadata":{"execution":{"iopub.status.busy":"2023-12-12T11:14:08.361319Z","iopub.execute_input":"2023-12-12T11:14:08.361676Z","iopub.status.idle":"2023-12-12T11:14:08.373482Z","shell.execute_reply.started":"2023-12-12T11:14:08.361646Z","shell.execute_reply":"2023-12-12T11:14:08.372361Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(0,\n 176,\n 'GGGAACGACUCGAGUAGAGUCGAAAAUUUCCUUCCAAAUCCUGAGGGAGAGAUAGAGGCGGAGGGUCUGGGGGAGGAAUUAAAACACAAGGUCUCCUCCCCUCUCGCCUGUCCGAACUUGGGGGCACCCCGGCUCGUACUUCGGUACGAGCCGGGGAAAAGAAACAACAACAACAAC')"},"metadata":{}}]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"class RNA_Dataset_Test(Dataset):\n    def __init__(self, df, mask_only=False, **kwargs):\n        self.seq_map = {'A':0,'C':1,'G':2,'U':3}\n        df['L'] = df.sequence.apply(len)\n        self.Lmax = df['L'].max()\n        self.df = df\n        self.mask_only = mask_only\n        \n    def __len__(self):\n        return len(self.df)  \n    \n    def __getitem__(self, idx):\n        id_min, id_max, seq = self.df.loc[idx, ['id_min','id_max','sequence']]\n        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n        L = len(seq)\n        mask[:L] = True\n        if self.mask_only: return {'mask':mask},{}\n        ids = np.arange(id_min,id_max+1)\n        \n        seq = [self.seq_map[s] for s in seq]\n        seq = np.array(seq)\n        seq = np.pad(seq,(0,self.Lmax-L))\n        ids = np.pad(ids,(0,self.Lmax-L), constant_values=-1)\n        \n        return {'seq':torch.from_numpy(seq), 'mask':mask}, \\\n               {'ids':ids}\n            \ndef dict_to(x, device='cuda'):\n    return {k:x[k].to(device) for k in x}\n\ndef to_device(x, device='cuda'):\n    return tuple(dict_to(e,device) for e in x)\n\nclass DeviceDataLoader:\n    def __init__(self, dataloader, device='cuda'):\n        self.dataloader = dataloader\n        self.device = device\n    \n    def __len__(self):\n        return len(self.dataloader)\n    \n    def __iter__(self):\n        for batch in self.dataloader:\n            yield tuple(dict_to(x, self.device) for x in batch)","metadata":{"execution":{"iopub.status.busy":"2023-12-12T11:14:08.375147Z","iopub.execute_input":"2023-12-12T11:14:08.376237Z","iopub.status.idle":"2023-12-12T11:14:08.394061Z","shell.execute_reply.started":"2023-12-12T11:14:08.376170Z","shell.execute_reply":"2023-12-12T11:14:08.392448Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class SinusoidalPosEmb(nn.Module):\n    def __init__(self, dim=16, M=10000):\n        super().__init__()\n        self.dim = dim\n        self.M = M\n\n    def forward(self, x):\n        device = x.device\n        half_dim = self.dim // 2\n        emb = math.log(self.M) / half_dim\n        emb = torch.exp(torch.arange(half_dim, device=device) * (-emb))\n        emb = x[...,None] * emb[None,...]\n        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n        return emb\n\nclass RNA_Model(nn.Module):\n    def __init__(self, dim=192, depth=12, head_size=32, **kwargs):\n        super().__init__()\n        self.emb = nn.Embedding(4,dim)\n        self.pos_enc = SinusoidalPosEmb(dim)\n        self.transformer = nn.TransformerEncoder(\n            nn.TransformerEncoderLayer(d_model=dim, nhead=dim//head_size, dim_feedforward=4*dim,\n                dropout=0.1, activation=nn.GELU(), batch_first=True, norm_first=True), depth)\n        self.proj_out = nn.Linear(dim,2)\n    \n    def forward(self, x0):\n        mask = x0['mask']\n        Lmax = mask.sum(-1).max()\n        mask = mask[:,:Lmax]\n        x = x0['seq'][:,:Lmax]\n        \n        pos = torch.arange(Lmax, device=x.device).unsqueeze(0)\n        pos = self.pos_enc(pos)\n        x = self.emb(x)\n        x = x + pos\n        \n        x = self.transformer(x, src_key_padding_mask=~mask)\n        x = self.proj_out(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2023-12-12T11:14:08.395524Z","iopub.execute_input":"2023-12-12T11:14:08.395869Z","iopub.status.idle":"2023-12-12T11:14:08.412251Z","shell.execute_reply.started":"2023-12-12T11:14:08.395840Z","shell.execute_reply":"2023-12-12T11:14:08.411161Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"df_test = pd.read_parquet(os.path.join(PATH,'test_sequences.parquet'))\nds = RNA_Dataset_Test(df_test)\ndl = DeviceDataLoader(torch.utils.data.DataLoader(ds, batch_size=bs, \n               shuffle=False, drop_last=False, num_workers=num_workers), device)\ndel df_test\ngc.collect()\n\nmodels = []\nfor m in MODELS:\n    model = RNA_Model() \n    model = model.to(device)\n    model.load_state_dict(torch.load(m,map_location=torch.device('cpu')))\n    model.eval()\n    models.append(model)","metadata":{"execution":{"iopub.status.busy":"2023-12-12T11:15:19.692444Z","iopub.execute_input":"2023-12-12T11:15:19.692865Z","iopub.status.idle":"2023-12-12T11:15:23.830434Z","shell.execute_reply.started":"2023-12-12T11:15:19.692831Z","shell.execute_reply":"2023-12-12T11:15:23.829181Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"ids,preds = [],[]\nfor x,y in tqdm(dl):\n    with torch.no_grad(),torch.cuda.amp.autocast():\n        p = torch.stack([torch.nan_to_num(model(x)) for model in models]\n                        ,0).mean(0).clip(0,1)\n        \n    for idx, mask, pi in zip(y['ids'].cpu(), x['mask'].cpu(), p.cpu()):\n        ids.append(idx[mask])\n        preds.append(pi[mask[:pi.shape[0]]])\n\nids = torch.concat(ids)\npreds = torch.concat(preds)\n\ndf = pd.DataFrame({'id':ids.numpy(), 'reactivity_DMS_MaP':preds[:,1].numpy(), \n                   'reactivity_2A3_MaP':preds[:,0].numpy()})\ndf.to_csv('submission.csv', index=False, float_format='%.4f') # 6.5GB\ndf.head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-12-12T11:15:24.818013Z","iopub.execute_input":"2023-12-12T11:15:24.818405Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8afe60407f3543d48425ddd5c4a76849"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/amp/autocast_mode.py:204: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n/opt/conda/lib/python3.10/site-packages/torch/nn/modules/transformer.py:544: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)\n  return torch._transformer_encoder_layer_fwd(\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}